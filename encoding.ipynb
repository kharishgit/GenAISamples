{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame({\"text\":[\"people watch cricket\",\"cricket watch cricket\",\"people give comment\",\"cricket give comment\"],\"output\":[1,1,0,0]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     people watch cricket\n",
       "1    cricket watch cricket\n",
       "2      people give comment\n",
       "3     cricket give comment\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bow.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary  {'people': 3, 'watch': 4, 'cricket': 1, 'give': 2, 'comment': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary \", bow.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix:\n",
      " [[0 1 0 1 1]\n",
      " [0 2 0 0 1]\n",
      " [1 0 1 1 0]\n",
      " [1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature matrix:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dummies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cricket give comment  cricket watch cricket  people give comment  \\\n",
      "0                 False                  False                False   \n",
      "1                 False                   True                False   \n",
      "2                 False                  False                 True   \n",
      "3                  True                  False                False   \n",
      "\n",
      "   people watch cricket  \n",
      "0                  True  \n",
      "1                 False  \n",
      "2                 False  \n",
      "3                 False  \n"
     ]
    }
   ],
   "source": [
    "ohe = pd.get_dummies(data['text'])\n",
    "print(ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = CountVectorizer(ngram_range=(2,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = bigram.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people watch': 7,\n",
       " 'watch cricket': 9,\n",
       " 'people watch cricket': 8,\n",
       " 'cricket watch': 2,\n",
       " 'cricket watch cricket': 3,\n",
       " 'people give': 5,\n",
       " 'give comment': 4,\n",
       " 'people give comment': 6,\n",
       " 'cricket give': 0,\n",
       " 'cricket give comment': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 0],\n",
      "        [0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Categories represented as integers\n",
    "categories = torch.tensor([0, 1, 2, 0, 2])  # e.g., 0: Red, 1: Green, 2: Blue\n",
    "\n",
    "# Number of unique categories\n",
    "num_categories = 3  # Adjust this based on your dataset\n",
    "\n",
    "# One-hot encoding\n",
    "one_hot_encoded = torch.nn.functional.one_hot(categories, num_classes=num_categories)\n",
    "\n",
    "print(one_hot_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "[[0.         0.37420726 0.         0.         0.49203758 0.37420726\n",
      "  0.         0.37420726 0.58121064 0.        ]\n",
      " [0.         0.         0.37420726 0.49203758 0.         0.37420726\n",
      "  0.         0.37420726 0.58121064 0.        ]\n",
      " [0.42439575 0.32276391 0.32276391 0.         0.         0.\n",
      "  0.42439575 0.         0.50130994 0.42439575]]\n",
      "\n",
      "Feature Names:\n",
      "['and' 'cat' 'dog' 'log' 'mat' 'on' 'played' 'sat' 'the' 'together']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the log\",\n",
    "    \"the cat and the dog played together\"\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_dense = tfidf.todense()\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_dense)\n",
    "\n",
    "print(\"\\nFeature Names:\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "Found existing installation: gensim 4.3.3\n",
      "Uninstalling gensim-4.3.3:\n",
      "  Successfully uninstalled gensim-4.3.3\n",
      "Collecting gensim==4.3.3\n",
      "  Using cached gensim-4.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/harishk/anaconda3/envs/pytorch-env/lib/python3.11/site-packages (from gensim==4.3.3) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/harishk/anaconda3/envs/pytorch-env/lib/python3.11/site-packages (from gensim==4.3.3) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/harishk/anaconda3/envs/pytorch-env/lib/python3.11/site-packages (from gensim==4.3.3) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /Users/harishk/anaconda3/envs/pytorch-env/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim==4.3.3) (1.17.0)\n",
      "Using cached gensim-4.3.3-cp311-cp311-macosx_11_0_arm64.whl (24.0 MB)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy -y\n",
    "!pip install numpy==1.26.4\n",
    "!pip uninstall gensim -y\n",
    "!pip install gensim==4.3.3\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-100\")  # Smaller GloVe model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harishk/gensim-data\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "print(api.BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model[\"sunny\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.95967  ,  0.30795  ,  0.90052  ,  1.0364   ,  0.0034906,\n",
       "       -0.80758  , -1.139    ,  0.81109  , -0.67857  ,  0.52609  ,\n",
       "       -0.072252 , -0.75613  ,  0.52847  ,  1.0927   , -0.51895  ,\n",
       "       -0.21335  ,  0.18184  ,  0.40038  , -0.6547   ,  0.34626  ,\n",
       "        0.92248  , -0.25001  ,  1.1779   ,  0.61006  ,  0.029763 ,\n",
       "        0.4378   ,  0.53647  ,  0.68827  ,  0.14582  , -0.27446  ,\n",
       "       -0.50289  ,  1.0366   , -0.29851  , -0.32927  ,  0.24944  ,\n",
       "       -0.33779  ,  0.0083236, -0.21373  , -0.45898  , -0.23441  ,\n",
       "       -1.2958   ,  0.74799  ,  0.78192  , -0.75644  ,  0.84375  ,\n",
       "       -0.51725  ,  1.0952   ,  0.51768  ,  0.27906  , -0.033519 ,\n",
       "       -0.1573   ,  0.7396   ,  0.39775  ,  1.132    , -0.69279  ,\n",
       "       -2.0093   , -1.1731   , -0.14204  ,  1.5658   , -0.097956 ,\n",
       "       -0.071165 , -0.18906  ,  0.037441 ,  0.48037  ,  0.29248  ,\n",
       "        0.9216   ,  0.33285  ,  0.30963  ,  1.1272   ,  0.19965  ,\n",
       "        0.47058  ,  0.019022 , -0.27432  , -0.49782  , -0.29441  ,\n",
       "        0.28578  , -0.54893  , -0.18968  , -1.3139   ,  0.010304 ,\n",
       "        0.58306  , -0.19652  ,  0.099424 , -0.27646  , -0.50329  ,\n",
       "        0.12081  , -1.1012   , -0.23784  , -0.3516   ,  0.36723  ,\n",
       "        0.25884  , -0.19463  , -0.27582  , -0.70492  , -0.69454  ,\n",
       "        0.70624  ,  0.2283   ,  0.081052 ,  0.1351   ,  0.14388  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['india']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pakistan', 0.8370324373245239),\n",
       " ('indian', 0.780203104019165),\n",
       " ('delhi', 0.7712194323539734),\n",
       " ('bangladesh', 0.7661641240119934),\n",
       " ('lanka', 0.7639288306236267),\n",
       " ('sri', 0.7506584525108337),\n",
       " ('australia', 0.704209566116333),\n",
       " ('malaysia', 0.6796303391456604),\n",
       " ('nepal', 0.6761943697929382),\n",
       " ('thailand', 0.6671633124351501)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46522087"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('india','america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot select a word from an empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoesnt_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.11/site-packages/gensim/models/keyedvectors.py:1140\u001b[0m, in \u001b[0;36mKeyedVectors.doesnt_match\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdoesnt_match\u001b[39m(\u001b[38;5;28mself\u001b[39m, words):\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Which key from the given list doesn't go with the others?\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank_by_centrality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.11/site-packages/gensim/models/keyedvectors.py:1120\u001b[0m, in \u001b[0;36mKeyedVectors.rank_by_centrality\u001b[0;34m(self, words, use_norm)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectors for words \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m are not present in the model, ignoring these words\u001b[39m\u001b[38;5;124m\"\u001b[39m, ignored_words)\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m used_words:\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot select a word from an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1121\u001b[0m vectors \u001b[38;5;241m=\u001b[39m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(word, norm\u001b[38;5;241m=\u001b[39muse_norm) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m used_words])\u001b[38;5;241m.\u001b[39mastype(REAL)\n\u001b[1;32m   1122\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_vector(vectors, post_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot select a word from an empty list"
     ]
    }
   ],
   "source": [
    "model.doesnt_match([\"Me\",\"You\",\"Us\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8551837205886841),\n",
       " ('queen', 0.7834413647651672),\n",
       " ('monarch', 0.6933802366256714),\n",
       " ('throne', 0.6833109259605408),\n",
       " ('daughter', 0.680908203125),\n",
       " ('prince', 0.6713142991065979),\n",
       " ('princess', 0.664408266544342),\n",
       " ('mother', 0.6579325199127197),\n",
       " ('elizabeth', 0.6563301086425781),\n",
       " ('father', 0.6392418742179871)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec=model['king'] - model['man'] + model['woman']\n",
    "model.most_similar(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
